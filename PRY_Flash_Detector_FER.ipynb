{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\img\\mioti.png\">   \n",
    "\n",
    "\n",
    "\n",
    "# Proyecto Reconocimiento Facial: Detector de Caras Flash\n",
    "\n",
    "<img src=\"./img/emociones.png\" style=\"width: 800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "Este notebook es necesario para el POC de la solución Móvil. Utiliza Flask para levantar un servidor en local y así se puede consultar una página HTML desde el dispositivo móvil, desde reconocer a la persona y sus emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import Response\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model=\"./model/vgg-face-model-v4.json\"\n",
    "file_weights=\"./model/vgg-face-v4.h5\"\n",
    "class_labels=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(file_model, 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = tf.keras.models.model_from_json(model_json)\n",
    "model.load_weights(file_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reconocedor_facial=cv2.face.EigenFaceRecognizer_create()\n",
    "reconocedor_facial.read('./model/modelo_reconocimiento_caras.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Javier', 'Juan Pedro', 'Ricardo']\n"
     ]
    }
   ],
   "source": [
    "data_path='./reconocimiento'\n",
    "lista_gente=os.listdir(data_path)\n",
    "print(lista_gente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_with_backgroud(img, text, x, y, font_scale, thickness=1, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            background=(175,50,200), foreground=(255,255,255), box_coords_1=(-5,5), box_coords_2=(5,-5)):\n",
    "    (text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)[0]\n",
    "    box_coords = ((x+box_coords_1[0], y+box_coords_1[1]), (x + text_width + box_coords_2[0], y - text_height + box_coords_2[1]))\n",
    "    cv2.rectangle(img, box_coords[0], box_coords[1], background, cv2.FILLED)\n",
    "    cv2.putText(img, text, (x, y), font, fontScale=font_scale, color=foreground, thickness=thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    if len(faces) == 0:\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for idx,face in enumerate(faces):\n",
    "        x,y,w,h = face\n",
    "    \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(175,50,200),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_CUBIC)\n",
    "        roi_gray_face = cv2.resize(roi_gray, (150, 150), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        if np.sum([roi_gray]) != 0.0:\n",
    "            roi = roi_gray.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "        \n",
    "        #para hacer la prediccion hay que cambiar el tamaño a la imagen\n",
    "        \n",
    "            #Predicción de persona\n",
    "            result=reconocedor_facial.predict(roi_gray_face)\n",
    "            \n",
    "            #Predicción de emoción\n",
    "            preds = model.predict(roi)[0]\n",
    "            \n",
    "            if result[1]<10000:\n",
    "                label = f'Persona {lista_gente[result[0]]} EMOCION {class_labels[preds.argmax()]}'  \n",
    "            else:\n",
    "                label = f'Persona Desconocido EMOCION {class_labels[preds.argmax()]}'\n",
    "\n",
    "            draw_text_with_backgroud(img, label, x + 5, y, font_scale=0.4)\n",
    "            if (idx==1):\n",
    "                draw_text_with_backgroud(img, label, x + 5, y, font_scale=0.4, background=(15,150,200), foreground=(255,255,255), box_coords_1=(-7,7), box_coords_2=(7,-7))\n",
    "        else:\n",
    "            draw_text_with_backgroud(img, \"No Face Found\", x + 5, y, font_scale=0.4)\n",
    "   \n",
    "            \n",
    "    return (x,w,y,h), roi_gray, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        rect, face, image = face_detector(frame)\n",
    "\n",
    "    \n",
    "        res = cv2.resize(image, dsize=(800,600),interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.namedWindow(\"Reconocedor de Emociones\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Reconocedor de Emociones\", res)\n",
    "        \n",
    "        #Se comprime imagen y se almacena en memoria\n",
    "        (flag,encodedImage)=cv2.imencode('.jpg',frame)\n",
    "        #Si la imagen no fué codificada con éxito\n",
    "        if not flag:\n",
    "            continue\n",
    "        yield(b'--frame\\r\\n' b'Content-Type:image/jpeg\\r\\n\\r\\n'+bytearray(encodedImage)+b'\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "\n",
    "def index():\n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/video_feed\")\n",
    "\n",
    "def video_feed():\n",
    "    return Response(generate(),mimetype='multipart/x-mixed-replace;boundary=frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Jan/2022 21:12:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:12:55] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:13:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:13:25] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:13:32] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:14:41] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:14:50] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:16:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/Jan/2022 21:16:22] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.relase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
